# -*- coding: utf-8 -*-
"""Crack_Detectioin_CNN_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GVG6nn-9DG3-mX_vh2zrEGOd3L_ZSMM4
"""

# 0. Set up the environment

import os
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Colab Notebooks'
import zipfile
import os

zip_path = 'Concrete Crack Images for Classification.zip'
extract_to = '/content/crack_images1'

os.makedirs(extract_to, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("Zip file extraction completeï¼")

!ls /content/crack_images1
!ls '/content/crack_images1/Concrete Crack Images for Classification'

# 1. Set image parameters / è®¾ç½®å‚æ•°
image_size = 120  # Resize target size for images
base_path = '/content/crack_images1/Concrete Crack Images for Classification'
categories = ['Negative', 'Positive']
max_images_per_class = 20000  # Max images per class to load

# 2. Load and preprocess images with tone equalization and enhancement / å›¾åƒè¯»å– + è‰²è°ƒå‡è¡¡ + ç°åº¦è½¬æ¢
def load_and_process_images(folder_path):
    data = []
    for label_index, label in enumerate(categories):
        class_folder = os.path.join(folder_path, label)
        count = 0
        for filename in os.listdir(class_folder):
            if count >= max_images_per_class:
                break
            img_path = os.path.join(class_folder, filename)
            img = cv2.imread(img_path)

            if img is not None:
                # Equalize / è‰²è°ƒå‡åŒ–
                yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                yuv[..., 0] = cv2.equalizeHist(yuv[..., 0])
                eq_img = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)

                # Invert if image is too bright / ç°åº¦è½¬æ¢
                if np.mean(gray_img) > 127:
                    gray_img = 255 - gray_img

                # Denoise with Gaussian blur / é«˜æ–¯æ¨¡ç³Š
                gray_img = cv2.GaussianBlur(gray_img, (3, 3), 0)

                # Resize to uniform size / å°ºå¯¸è°ƒæ•´
                resized = cv2.resize(gray_img, (image_size, image_size))

                # Append image and label / ä¿å­˜å›¾åƒä¸Žæ ‡ç­¾
                data.append([resized, label_index])
                count += 1

    return np.array(data, dtype=object)

    # Load dataset after function definition
    dataset = load_and_process_images(base_path)

# 3. Split features and labels + normalize / åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾ï¼Œå¹¶å½’ä¸€åŒ–
X, Y = [], []
for img, lbl in dataset:
    X.append(img)
    Y.append(lbl)
X = np.array(X).reshape(-1, image_size, image_size, 1) / 255.0
Y = np.array(Y)

# 4. Split into training and validation sets / è®­ç»ƒé›†/éªŒè¯é›†åˆ’åˆ†
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=42)

# 5. Define CNN model structure / CNNæ¨¡åž‹å®šä¹‰
model = Sequential([
    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]),
    MaxPooling2D(),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(),

    Conv2D(256, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(),

    Conv2D(256, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.4),
    BatchNormalization(),
    # Output layer for 2 classes
    Dense(2, activation='softmax')
])

# Compile model
model.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Data augmentation setup
aug = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.05,
    height_shift_range=0.05,
    zoom_range=0.1
)
aug.fit(X_train)

"""It helps us â€œmake more training pictures.â€ For example, it turns, shifts, or zooms the original pictures a little to create new ones that look different but are still similar. This way, the model gets smarter and can recognize cracks even in pictures it hasn't seen before."""

# 6. Train the model / æ¨¡åž‹è®­ç»ƒ
history = model.fit(aug.flow(X_train, Y_train, batch_size=64),
                    epochs=15,
                    validation_data=(X_val, Y_val),
                    verbose=2)

# 7. Plot training and validation accuracy/loss / ç»˜å›¾
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.legend()
plt.tight_layout()
plt.show()

# 8. Print classification report / åˆ†ç±»æŠ¥å‘Š
val_preds = model.predict(X_val)
val_labels = np.argmax(val_preds, axis=1)
print(classification_report(Y_val, val_labels, target_names=categories))

import glob

# 9. Prediction function for single image
def test_accuracy_on_folder(folder_path):
    test_images = glob.glob(os.path.join(folder_path, "*"))  # Get list of all image files in folder
    total = len(test_images)

    # Output = ðŸš§ if you don't have a correct input
    if total == 0:
        print("Testing image not available / Test imageä¸å­˜åœ¨")
        return

    crack_count = 0
    no_crack_count = 0

    for path in test_images:
        img = cv2.imread(path)  # Load each image
        if img is None:
            continue

        # Same preprocessing as training: tone equalization, grayscale, inversion
        yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
        yuv[..., 0] = cv2.equalizeHist(yuv[..., 0])
        eq_img = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        gray_img = cv2.cvtColor(eq_img, cv2.COLOR_BGR2GRAY)

        if np.mean(gray_img) > 127:
            gray_img = 255 - gray_img

        # Resize and normalize
        gray_img = cv2.resize(gray_img, (image_size, image_size))
        gray_img = gray_img.reshape(1, image_size, image_size, 1) / 255.0

        # Make prediction
        prediction = model.predict(gray_img)[0]
        if prediction[1] > prediction[0]:
            crack_count += 1
        else:
            no_crack_count += 1

    print("\n=== Test Summary ===")
    print(f"Total: {total}")
    print(f"Crack: {crack_count}")
    print(f"No Crack: {no_crack_count}")
    print(f"Crack percentage: {crack_count / total:.2%}")
    print(f"No Crack percentage: {no_crack_count / total:.2%}")

# Run
test_accuracy_on_folder("/content/drive/MyDrive/Colab Notebooks/test_crack")